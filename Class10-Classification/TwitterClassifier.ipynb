{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e4d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import requests\n",
    "from nltk.corpus import stopwords # stopword examples, 'its', 'on', 'the', etc <---- will be helpful later\n",
    "# most pythonistas will rename pandas as pd, numpy as np, and datetime as dt for short (you don't have to)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d2e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file with keys and set the path to your credentials JSON file\n",
    "# you'll need to replace my file with yours\n",
    "credentials = \"keys.json\"\n",
    "with open(credentials, \"r\") as keys:\n",
    "    api_tokens = json.load(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c56349",
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = api_tokens[\"bearer_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab45e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only want status info so we won't need the higher level access\n",
    "client = tweepy.Client(bearer_token=bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9801c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_rangers = client.search_recent_tweets(\n",
    "    query = \"Rangers -is:retweet\",  # searches for #WPP while ignoring retweets\n",
    "    max_results = 100\n",
    ")\n",
    "\n",
    "tweets_rangers.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00488191",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranger_tweets = []\n",
    "for tweet in tweets_rangers.data:\n",
    "    ranger_tweets.append(tweet.text)\n",
    "    \n",
    "ranger_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908df4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_charles = client.search_recent_tweets(\n",
    "    query = \"King Charles -is:retweet\",  # searches for #WPP while ignoring retweets\n",
    "    max_results = 100\n",
    ")\n",
    "\n",
    "tweets_charles.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a78a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "charles_tweets = []\n",
    "for tweet in tweets_charles.data:\n",
    "    charles_tweets.append(tweet.text)\n",
    "    \n",
    "charles_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45c25a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def get_features(text):\n",
    "    # create array of words\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    s_words = stopwords.words('english')\n",
    "    keywords = dict([(w, True) for w in words if w not in s_words and not w.isdigit() and '/' not in w])\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "get_features(charles_tweets[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ced25",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_features = {'rangers': [], 'King Charles': []}\n",
    "\n",
    "for tweet in ranger_tweets:\n",
    "    features = get_features(tweet)\n",
    "    label_features['rangers'].append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b4255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in charles_tweets:\n",
    "    features = get_features(tweet)\n",
    "    label_features['King Charles'].append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b193a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_features['rangers'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac4d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# split the data into training / test sets -> 75/25% split\n",
    "def split_label_feats(label_features):\n",
    "    train_feats = []\n",
    "    test_feats = []\n",
    "    \n",
    "    for label in label_features:\n",
    "        features = label_features[label]\n",
    "        cutoff = math.floor(len(features)*.8)\n",
    "        train_feats.extend([(f, label) for f in features[:cutoff]])\n",
    "        test_feats.extend([(f, label) for f in features[cutoff+1:]])\n",
    "\n",
    "    return train_feats, test_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c9d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = split_label_feats(label_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f6698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "nb = NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f15ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1_features = get_features(\"Whatever he meant by it, he spoke for the country when he greeted Liz Truss. ‘Dear, oh dear’ just about sums things up.\")\n",
    "nb.classify(ex1_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8935be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2_features = get_features(\"Haven't seen them fold as badly as that since, oh, about 2012\")\n",
    "nb.classify(ex2_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88796915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "from nltk.classify.util import accuracy\n",
    "\n",
    "accuracy(nb, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting classification probability of each label\n",
    "probs = nb.prob_classify(test_set[6][0])\n",
    "\n",
    "print(probs.samples())\n",
    "print('chosen class:',probs.max())\n",
    "print('P(rangers)=',probs.prob('rangers'))\n",
    "print('P(King Charles)=',probs.prob('King Charles'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256484f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5013d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more information on the chosen label\n",
    "\n",
    "nb.show_most_informative_features(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
