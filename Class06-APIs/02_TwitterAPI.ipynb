{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09808e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import requests\n",
    "from nltk.corpus import stopwords # stopword examples, 'its', 'on', 'the', etc <---- will be helpful later\n",
    "# most pythonistas will rename pandas as pd, numpy as np, and datetime as dt for short (you don't have to)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317892e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file with keys and set the path to your credentials JSON file\n",
    "# see example.json for formatting\n",
    "# you'll need to replace my file with yours\n",
    "credentials = \"keys.json\"\n",
    "with open(credentials, \"r\") as keys:\n",
    "    api_tokens = json.load(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2699c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the keys and assign each to a variable\n",
    "bearer_token = api_tokens[\"bearer_token\"]\n",
    "api_key = api_tokens[\"api_key\"]\n",
    "api_secret = api_tokens[\"api_secret\"]\n",
    "access_token = api_tokens[\"access_token\"]\n",
    "access_secret = api_tokens[\"access_secret\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d726db",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(\n",
    "    bearer_token=bearer_token,\n",
    "    consumer_key=api_key,\n",
    "    consumer_secret=api_secret,\n",
    "    access_token=access_token,\n",
    "    access_token_secret=access_secret,\n",
    "    return_type = requests.Response\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b2836d",
   "metadata": {},
   "source": [
    "Let's look up the 100 most recent tweets using #London\n",
    "<br/>We're going to use the search_recent_tweets() function and 5 parameters, they are:\n",
    "<br/><b>q: </b>Short for query, <a href=\"https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query\">learn more about building queries here</a>\n",
    "<br/><b>max_results: </b>The maximum number of search results to be returned by a request. A number between 10 and 100. By default, a request response will return 10 results.\n",
    "<br/><b>tweet_fields: </b><a href=\"https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet\">See all tweet fields here</a>\n",
    "<br/><b>user_fields: </b><a href=\"https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/user\">See all user fields here</a>\n",
    "<br/><b>expansions: </b>This field will allow us to include the user_field values. <a href=\"https://docs.tweepy.org/en/latest/expansions_and_fields.html\">Learn more about expansions here</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f90d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = client.search_recent_tweets(\n",
    "    query = \"#WPP -is:retweet\",  # searches for #London while ignoring retweets\n",
    "    max_results = 100,\n",
    "    tweet_fields = ['author_id', 'created_at', 'text', 'source', 'lang', 'geo'],\n",
    "    user_fields = ['name','username','location','verified'],\n",
    "    expansions = 'author_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c48b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_dict = tweets.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a1a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd203e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract 'data' from dictionary, this will exclude the metadata\n",
    "tweets_data = tweets_dict['data']\n",
    "tweets_users = tweets_dict['includes']['users']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee45546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcdadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e29cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tweets_data))\n",
    "print(len(tweets_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b80c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the different numbers let's us know some users did multiple tweets with #WPP\n",
    "# transform to pandas dataframe\n",
    "df_data = pd.json_normalize(tweets_data)\n",
    "df_users = pd.json_normalize(tweets_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94d043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b421de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad81750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to merge these two data frames together. \n",
    "# I can see author_id in my data dataframe, and id in my users dataframe is what connect the two\n",
    "# let's make sure both columns use 'author_id' so pandas can merge the two\n",
    "df_users.rename(columns={'id': 'author_id'}, inplace=True)\n",
    "df_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec4bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I can merge our two DataFrames\n",
    "df_merged = df_data.merge(df_users, on='author_id')\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c683c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the created_at time is a little difficult to read so let's fix that\n",
    "df_merged[\"created_at\"] = df_merged[\"created_at\"].dt.strftime('%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c4a0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this didn't work!\n",
    "# let's just the type value of \"created_at\"\n",
    "print(type(df_merged.iloc[0].created_at))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061388ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's a string, so we need to convert to this a DateTime object first\n",
    "df_merged['created_at'] = pd.to_datetime(df_merged['created_at'])\n",
    "df_merged[\"created_at\"] = df_merged[\"created_at\"].dt.strftime('%d-%m-%Y %H:%M')\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15137a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# better!\n",
    "# I also don't care about the ids anymore, so let's get rid of those\n",
    "# 1 is the axis number (0 for rows and 1 for columns.)\n",
    "df_merged.drop(['author_id','id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bf770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# that's a lot better!\n",
    "# now let's save our data in pickled format - so that we don't have to grab it again if our machine crashes\n",
    "\n",
    "import pickle\n",
    "path = 'twitter' + dt.datetime.now().strftime(\"%Y-%m-%d_%I-%M-%S_%p\") + '.pkl'\n",
    "df_merged.to_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5803aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute a collection of all words from all tweets\n",
    "# this one takes a min or two to run\n",
    "\n",
    "words = []\n",
    "for text in df_merged['text']:\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words() or 'http' in word or word == '#WPP':\n",
    "            continue # skip if word is a link\n",
    "        else:\n",
    "            words.append(word)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c251d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find the most frequent words in these tweets\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "c = Counter(words)\n",
    "print(c.most_common()[:10])  # top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e8b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "pt = PrettyTable(field_names=['Word', 'Count']) \n",
    "c = Counter(words)\n",
    "[ pt.add_row(kv) for kv in c.most_common()[:10] ]\n",
    "pt.align['Word'], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
    "print(pt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
